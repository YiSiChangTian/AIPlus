# 哈尔滨工业大学集成电路刘同学采访记录

**采访视频见B站：逸思长天，采访PPT见本工程的document文件夹下**

采访时间：2024年5月16日

嘉宾卢同学代号：Guest

主持人AFAN代号：Host

H：OK，我看时间也差不多了，那我们就正式开始。首先欢迎各位同学参加我们逸思长天举办的“人工智能+百行交流”的活动。然后我是今天晚上的主持人AFAN。我们已经交流过环境、冶金、水产、材料学科的同学收获了很多行业相关的知识。那有兴趣的小伙伴呢，都可以去我们的B站账号“逸思长天”中去收看回放，包括我们今天的直播的视频，我们也会剪辑后发布到B站中。

H：那么今天呢，我们很高兴邀请到哈尔滨工业大学博士刘老师来和我们聊聊他眼中的集成电路和人工智能相结合的应用。刘老师的研究方向是三维存储器特性分析平台及测试数据的可视化、三维存储器存储单元电学模型设计及可靠性仿真研究，以及封装基板热力耦合及微区应力分析。那么在待会的分享过程中呢，同学们可以在讨论区打字交流。提问分享结束后，会预留时间给大家讨论交流。那我这边就把舞台交给刘老师，刘老师可以开始共享屏幕了。

G：OK，可以啊。好，首先非常感谢AFAN邀请我做这次报告。那么今天跟大家主要来分享集成电路行业中人工智能技术的运用。那刚刚AFAN也介绍我了，这边我跳过了。今天报告主要分以下几个部分的内容：首先介绍一下行业，然后再介绍一些创新路径，最后介绍一些应用。

G：首先介绍一下我自己吧。我是2013年从哈工大材料学这个专业博士毕业，然后呢一直在这个产业里边工作。20年的时候呢去到一个学校，然后现在在做一个老师。那么我自己呢实际上是从毕业开始就一直从事失效分析相关的工作。然后现在每年也在接一些技术培训，这个是为了维持自己的一个行业的地位。然后也在做一些设备的开发，当然这个就是为了赚点小钱了。然后呢也还是想给行业留点东西，所以也在就是组织一些资料，组织一些材料，然后想做一个失效分析的手册。

G：那么首先介绍一下这个整个的集成电路的行业。那么集成电路行业呢从源头来看的话主要是芯片设计，然后呢会把设计图纸给这个晶圆厂进行晶圆的生产。然后那个晶圆厂生产好之后呢，会把晶圆送到封测厂进行封装，最后做测试。那么在整个这些生产工艺的过程中，包括生产出来之后的成品都会进行一些测试。那么测试呢就会产生一些不良，也就是达不到测试的要求产品。那么这个东西呢是不能卖给客户的，所以呢要在这个厂内进行一些销毁或者是我们叫loss掉，就是淘汰掉。那么中间产生出来的这些不良品呢，我们把它称为reject，rejection的意思。然后这些不良品就会做这个失效分析。所以失效分析呢在整个集成电路这个行业还是应用的比较广泛的。

G：那么一个失效分析实验室呢其实最主要的还是有一些设备。那像如果要是做材料的同学可能对这个设备还是比较了解的，就像我们有这个样品制备的，比方说这种磨抛机或者用化学物理的方法去开盖，然后再用这个低倍的或者高倍的光学显微镜观察，然后用x射线包括超声波扫描，包括电子扫描电子显微镜。然后更高阶的可能会用到像这个聚焦离子束，然后包括透射电镜去做这个形貌的观察，然后也会那个能谱做成分分析。然后包括会做一些电性的一些分析。然后实际上分析最有特色的就是缺陷定位的这一块的设备。那我自己在外边公司做开发的其实也是这一块的设备，我们把它称为热点设备，其中最主要的是靠热或者靠光来成像的。

G：那么在一个厂工厂里边或者在一个实验室里边做失效分析的人员呢，实际上大部分都是学材料出身的，当然也有学微电子或者学化学的这个人。然后学历呢也是参差不齐，那也有就是大专毕业生可能过来从技术员做起，然后也有就是本科生或者硕士生毕业过来做工程师这样子。那失效分析设备呢，整个整体来说是比较贵的，一般来说一台设备都要上百万。然后像一个起步阶段的就是相对来说设备不是很全的这个失效分析实验室的话呢，基本上也接近千万的水平。然后像一些比较高级的像我待过的一些实验室呢，基本上设备都是过亿的。

G：那失效分析呢其实在我刚刚介绍的那些PPT里边也有提到，就是它是贯穿了整个这个芯片的产品从设计到制造到啊最后到客户终端客户手里边，它是贯穿了整个的这个生命周期。那么比方说样品送到客户那边最后坏掉了或者批量的这个出现这种失效，那么就会发生一些客诉，然后叫customer claim。然后他就会把样品返回回来，这时候原厂会通过失效分析做一些这个报告，然后再反馈给客户到底是什么原因，是不是要赔款，是不是要退货，还是说是客户自己使用不当造成的。

G：然后包括工程上边就是生产工艺里边可能有些问题，那么工艺工程师一般来说是不会操作这些分析设备的，那么还是要到失效分析部门来做这个分析。然后包括来料的一个原材料缺陷的一个检测，那么这个呢就是工厂里边会有incoming quality这个部门叫IQC。那么IQC也会找失效分析部门来做分析。然后包括一些设计公司他的设计是否合理，那么失效分析公司都能帮助到他。然后特别是这个可靠性这个部门，就是样品在出厂之前一般都会做可靠性认证，我们叫qualification。那么这个qualification就是各种可靠性项目加电的加温度的加湿度的这样的测试，那么会有很多的这个不良，那么下来之后也都是要靠实验分析来找到它的一个原因，然后做出相应的改善，之后再次做那个qualification，然后一旦通过了才可以进入到量产这个环节。

G：所以整个来看的话，失效分析的这个服务的对象和整个的价值还是比较高的。我们就是提到这个行业呢，其实我们要先问一个问题，就是什么叫失效分析。那么这个是有严格的定义，就是产品不能完成它设计的功能，那么这个我们就称其为失效。那么失效呢其实不是重点，重点是我们怎么样通过失效分析来找到这个失效的一个原因。

G：那么在失效分析行业里边呢，我们一般会简单的把这个失效分析手法把它分成PFA和EFA。那么EFA就是电型的失效分析，一般来说我们会用示波器或者用这个IV Curve，然后用这个热点设备来做这个故障的隔离。然后每换一种这个分析的手段呢，我们都希望我们能把怀疑的范围缩小100倍。那么最终我们可以从一个毫米级的一个怀疑的区域一直能缩到啊可能10个纳米或者100多个纳米这样的一个范围尺度内，然后我们才能找到真正的物理失效点。那么PFA呢主要就是用一些物理或者化学的手段，比如说开盖啊或者是磨抛啊或者是FIB切这样的手段来找到物理失效点，最后把它给呈现出来。

G：那么失效分析的研究目标呢，就是或者说我们追求的目标其实就是找到这个根本原因，就是所谓的Root Cause。那么其实呢失效分析在整个这个国内就是这几年开始重视起来了。那么前几年甚至10年前我刚进入到这个领域的时候呢，实际上除了外企，因为我一开始在韩企后来在美企，国内的企业基本上是不是很重视这一块的。那么这几年呢，随着就是芯片国产化的进程的推进，那么大家在不断的去改善自己工艺的过程中发现失效分析越来越重要。那美国人是走过这条路的，所以他们对这块是非常非常的重视。那么找到这个失效分析的根因呢，实际上不是那么简单的，就是（它不是）发现一个物理失效点就能解释的，它涉及到方方面面。比方说这个背景调查，比方说共性的调查啊，然后包括要做一些仿真，然后包括做这个就是档案库的一些管理。那么这些拼图拼起来最后可能才能拼出一个真正的这个失效的原因，然后才能就是反馈给这个生产也好反馈给设计也好去做相应的改善。

G：那么我们这个行当就失效分析这个领域呢，基本上大家发的文章都是一些会议的文章，也就是大家都是很新鲜的一些发现，然后去跟这个工程师们去共享自己的一个想法或者一个新的分析的手段，新的设备。那么大家都会去这种顶级的会议去发表。那最顶尖的肯定就是ISTFA这个会议，其实只在美国办，但是也有二十几年的历史了。然后IPFA呢是最早是新加坡开始办起来的，然后它一般都会在中国国内办一期，然后在那个新加坡再办一期，之前在苏州也办过。那这个会议也相对来说相对ISTFA来说是弱一些，但是也算是顶级的，应该是top three吧，这个水平的一个会议。

G：好，那么接下来我就简单讲一些这个AI和这个芯片失效分析的一些结合的地方。嗯，当然我不是专业的了啊，然后我也都是通过一些文献，然后也是这次AFAN邀请我，然后我去调研调查了一些这个就是机器学习，然后包括这个深度学习这一块和这个失效分析的一个结合。

G：那首先呢就是一个3D X-ray的一种设备。那么这个呢实际上跟大家平时在医院里边用到的这个CT是差不多的，只不过我们是在失效分析领域呢是拿它来做这个样品的一个360度的一个扫描，一般来说180度也就够了。然后呢我们这个跟医院的CT不太一样的地方呢，就是我们这个3D X-ray它是可以变焦的。那么这个其实是蔡司独家的技术，为了提高这个分辨率啊。然后我们可以看到啊，它是一个无损的一个分析，那么扫出来的这个图像呢实际上是经过计算得出的。那么之前这种计算呢一般就叫重构三维重构，它需要大量的这个计算量。然后之前大家用的基本上都是一个FDK的一种算法，然后我在文献调查的时候发现他们近两年吧已经开始产生了一些通过深度学习的一个方式的一种就是算法的提升。那么通过这个结果我们也能看得出来一方面呢，这个针对学习的这种算法呢，它可以啊用更小的这个扫描时间，然后呢能获得更高的解析度。那么这个这种重构的方式呢其实上是超越了原来的这个FDK的一个传统的这个CT重构的这样一种方方法。

G：然后第二个就比较常见了在这个机器学习领域或者说在CV领域，那实际上就是做这个目标识别。那么设备设备呢是一个发光的一个热点设备，那具体的原理我就不解释了，大概就是说这个MOS管啊它在失效或者是在某些情况下它可能会发光。那我们通过一个微光的显微镜来捕捉到这个光点，然后呢给它叠加到这个原始的红外图像上，就把它作为一种热点。那么我们关注的呢就是有热点的这个地方这个区域可能会有失效的这个问题可能会有缺陷。然后实际上这个热点呢就是颜色就是就是有一种颜色在这边，但是通过机器学习呢实际上是可以把这个你的目标位置啊用这个框给它标出来，啊所以它是一种这个叫目标检测的这样的一种方式。然后这里边呢实际上这篇文献报导呢就是因为原始数据量的不够，所以呢他在训练模型的时候实际上他用了一些比较常见的比方说做镜像或者做旋转的方式给这个数据集扩容。然后呢用这个VGG16啊进行目标识别，啊所以都是比较常规的一些算法。

G：那接下来这个就是也是失效分析里边比较常用的一种设备就是超声波扫描。那超声波呢具体的原理啊我就不也也不提了，就其实就是靠这个超声作用在样品上，然后靠这个返回的信号或者靠穿透的信号来成像。但是它是一种扫描模式，就是它上面的这个探头呢会在这个样品表面扫过去，做这个Z字形的一个扫描的这个方式。然后在扫描的过程中成像，那么这个实际上我一开始是没有想到这个超声的这个设备是可以接入到这个就是机器学习的这种算法里面去的。因为我一开我我们在失效分析领域呢一般超声波扫描算是一个常规检查的设备，分辨率本身也不高。但是呢当我看到就是他结合了这个机器学习就像刚刚那个CT的那个设备类似结合了机器学习之后呢，就明显能感觉到它的一个就是解析度啊会提高了。那这个呢这篇文献呢基本上就是一个相对比较典型的就是他获得获取数据然后再从数据中间提取一些有用的信息然后再打标然后再做训练，这个是比较就是比较典型的一个失效分析就是那个机器学习的一个流程了。然后这边比较有趣的就是这个超声的这个信号呢，它基本上都是时间序列的，那么它当然就是天然的可以用这个RNN的这种网络来做训练，然后呢它后边又结合了一维的CNN然后包括LSTM这样的算法来做这个就是模型的一些这个训练。然后这个是另外一篇文献的报道，那么它这个用到了也是用这个超声信号作为输入，但是它用了ICA这样的算法就独立成分分析，然后中间也结合这个一维的CNN做这个分类器。然后它从这个整个超声波信号里边呢就提取出来了大概有十几个这个独立成分，然后呢其中有四个他认为适合这个有缺陷的这个凸点我们叫bump是这个CPU或者那个GPU它封装的一种形式，就是芯片下边这种小的bump然后呢焊在这个基板上。那么它用这个ICA呢就是分离出来这个独立成分呢最后就发现有缺陷的bump呢大概是有四个独立成分可能跟有缺陷的bump有关，然后有三种呢是跟这个无缺陷的有关，还有两种是跟这个背景有关。那么他把这些信号提出来之后呢给他叠加到原始的这个超声扫描的图像上面去，那么我们就可以清晰的看到这个缺陷在整个的这个超声扫描的这个图像上或者说在这个芯片样品上的一个分布。那么这个红色的位置就标示出了它整个这个封装啊这个工艺里边可能会产生的一些缺陷，那么比方说像这个气球里面会有一个大的void就气泡。

G：然后接下来这个呢是用这个失效分析的一些数据，比方说我们的这个样品生产出来之后呢实际上是有好有坏，那么我们一般会给它叫分bin就是做分类，好品的话我们一般把它叫bin one就是bin，然后有不良品呢我们也会给它分成比方说bin3 bin4 bin5...不同的bin呢就代表了不同的失效模式，比方说有这个我们叫呃stand by的这个失效也有这个chip ID读不出来的这种失效也有漏电的这种失效，那可能对应不同的bin啊。然后他这个示例呢就是把这个bin1的样品和这个就是已经做过实效分析然后已经成功了的这种样品，然后包括有一些EFA的做过这个电流测试的这种样品呢给他打包成一个数据集，然后呢也分成了这个training set然后验证集啊然后包括测试集这样的一个方式。然后它的数据呢主要就是提取了这些样品的一些电流值啊包括一些电流的峰值动态的一些电流值，然后作为输入，一共有大概32个这个数据，然后输入给一个ANN。ANN的话我的理解就是其实就是一层的神经网络，一层的神经网络。那么中间呢他就用了一个啊sigmoid做这个hidden layer，然后呢用这个tanh作为这个输出层输出，然后因为tanh呢我的理解的话就是它的大部分的数据都分布在1和-1之间，-1的附近而不是均匀的分布到-1跟那个就是整个的一个范围，然后就可以获获得一个yes or no的这样的一个判断。所以呢他把这些数据呢训练好之后就这个模型训练好之后呢，他有新的样品过来，那么他把这个32个这个电流提取出来之后他就可以喂给这个模型，然后看这个输出结果，如果是接近-1的话啊他就可能认为这个失效分析做成功的概率比较低，所以呢他就可以不做了，这样就会节省一些成本。然后如果要是接近1的话啊，那么他就觉得有价值，那就可以做这个失效分析。但是呢我关于这篇文献呢其实我也是大概五六年前读的了啊，正好这次AFAN邀请到我啊，就说想做一个跟机器学习相关的这么一个这个报告，然后我就想起这篇文献了，我就把自己之前读的这个做的文献笔记翻出来，啊实际上当时我就对他这个方法呢有一些考虑。一方面呢是我觉得他的这个层呀这个ANN的这种这种层数实在是太少了，实际上他的预测的结果我觉得准确率也不见得有多高，只不过可能就是替代了一些人为的一些因素了，就是人的话会有经验主义，机器学习总归是是机器嘛，他不会有一些就是情绪或者有一些解犯这种经验主义的错误。然后还有一个呢就主要是他的数据集的问题，因为呢我们看到它其实好品跟坏品选择的比例啊实际上是差不多的，虽然好品是多了一些，但是坏品呢没那么多对吧。但是呢对于整个的这个比方说我们生产100颗啊样品的话，实际上好品是占大多数的，然后失效品呢其实是占的一般来说都是少很少的一部分，我们一般都做这个就是良率的管控，那么一般来说都会卡到99.就是99.7%的这个样品都是好品，那剩下3%可能啊0.3%可能才是坏品，所以说失效品一般来说比例都是比较低的。所以我认为他选择数据集的时候呢，正常来说应该是要啊按照这个比例来选，同时呢在这个整个的失效品里边来看的话呢，失效分析的成功率啊其实也就是30%左右，像我这个水平稍微高一点然后呢做这个封装的失效分析多一些的话呢可能做到60%以上，但是大多数呢包括晶圆晶圆厂的这个失效分析工程师他的成功率基本上也就是三成到四成左右的这么一个水平。所以这个呃我不知道自己想的对不对，但是我觉得如果要考虑全样的话，那么数据集的话还是应该按照样品的这个出现的这个比例来选取可能会更好一点，覆盖性也会更广一点。

G：那么最后一个案例实际上也是之前我看上一篇文献的时候想到的一个事情，然后我就写在我的那个就是文献的笔记里边了，然后正好这次AFAN邀请我的时候呢，我就读了一篇综述，然后刚刚好在这篇综述的这个末尾看到了这样的一篇文献，其实跟我之前的想法基本上是很接近的，但是当时我没有去做这个事情。那么这个在搞学术经常就会遇到这种问题，就是你的idea你没有时间去做，或者你你没有条件去做，或者你也不知道怎么做，你只是有一个idea而已。但是呢就是世界上的聪明人很多，那人家就把这个活给干了，对吧。那这个呢实际上也蛮有趣的，一方面呢它的这个啊它用的是呢是我们叫工艺仿真的这个软件，就是所谓的TCAD的，那就是我们要仿用这个数学或者物理的公式我们来仿真出这个芯片工艺，就是这个晶圆生产的时候的一个情况。然后呢可以搭建在这个上面可以搭建器件，然后可以就是获取这个器件它的一个电特性，那么就像右边的这个一样我们会做建模，然后画网格，然后做这个公式的推导。那么最后他会给你反馈回来一个这个信号，主要就是我们这个案例里边主要就是看他的这个电流，然后包括他的一些MOS管的一些特性，包括这个阈值电压这些东西啊，这些都是比较重要的来就是量测工艺是否稳定的这样的一些指标。

G：然后它是通过TCAD的仿真软件给入不同的这个缺陷的位置，然后包括缺陷的大小，然后呢来在这个模型里边让它随机的分布或者是按照一定的规律来分布。分完了之后呢，它把这个模型的一个输出，也就是这些这些电压电流的这些信号，然后包括这些关键参数拿出来，然后作为数据集，然后喂给了这个一个随机森林的这么一个模型。然后呢达到了这个分类的效果，这个分类的结果就是我们这个叫FinFET嘛，就是这个鲨鱼鳍的这样的MOS管，这个都是先进工艺了，一般在这个22纳米往下的工艺里边都是用这个FinFET来做的。它的好处就是可以把这个MOS管竖起来了，然后可以进一步的缩小我们的关键尺寸。那它分类的结果实际上就是可以帮助判断这个缺陷到底是在这个鲨鱼鳍的内部还是在鲨鱼鳍的外部。那么这个呢往往对于先进工艺来说，因为它的MOS管现在最小的做到3纳米，当然我们可能大陆这边就是国内这边量产的话基本上也就是16纳米，像华为之前有那个也不知道是在哪生产的，据说是在那个深圳那边做的呃7纳米的还是10纳米的这个就是Mate60 Pro的那个芯片，对吧，那个CPU。然后单个的MOS管是非常小，基本上就是十几个纳米，可能两个MOS管来看的话可能就是二十几个纳米这么一个宽度。那在这么小的范围内啊，你要去找到这个缺陷，首先定位，然后再找到它，再把它给展示出来，实际上难度是非常高的。那么有这么的一个模型的话呢，如果我们在前期把这个MOS管的一些特性啊给它拿到，然后呢喂到这个已经训练出来的模型，然后大概能得到一个信息，就是到底是在这个FinFET内还是在这个FinFET外。那么这个其实是真的是很关键啊，然后特别是啊现在这种小的MOS管呢，先进工艺的我们之前提到的那些热点啦，然后包括这个超声啦，包括X-ray啦，这些东西都是做不到的，那些基本上能达到微米级的定位就已经很厉害了，都不到都没有到亚微米，基本上是这个几个微米甚至几十个微米这么一个范围。所以说要缩小到真正的纳米级的纳米尺度的这样的一个定位的手段基本上还是靠这样仿真，然后像我知道实际上他们除了做这样机器学习的一个分布的话呢，他们可能还真的就是靠这个器件的一个仿真，来就是帮助到失效分析工程师找到具体的位置。当然有这个之后我觉得会更便捷一些，更便捷一些。

G：所以呢，就是我通过之前一些文献的调研吧，然后我也发现其实像这个机器学习也好，深度学习也好，呃在这个我们这个集成电路失效分析这个领域其实已经有了一些实际的应用。但是呢在设备端就是失效分析设备端其实我还没有看到，没有看到。可能其实也是同行给机会，就是大部分做设备的人呢他都是就是吃老本，就是很多很多失效分析设备他可能十几二十年前就是长那个样子的。啊那他实际上变动的也大部分也就是系统，就比方说软件他从这个Windows XP啊变成Windows 9 Windows，然后再给你换成Windows，大概就是这么一个提升，可能加点触摸屏加点什么的。但是它的传感器实际上包括相机可能一直没有太大的一个跃升，然后基本的原理嗯都是上个世纪八九十年代就已经就是说的很清楚的一些东西了。然后但是CT是一个例外，因为CT的话确实需要有一些就是计算的能力，要不然的话呃计算的时间太长，然后可能用起来不是那么方便。

G：然后呢其实像我之前就是一直在社会一些领域工作，我觉得就是像ANN这样的模型实际上是不是很实用啊，当然这个也是没有办法的办法。因为呢对于失效分析这个领域来说呢，它的设备的种类非常非常多，然后数据呢有像这个图片的也有这个像这种IV Curve就是一种Curve一种那个就是我们像那个画那个点线图一样的这种绘图。然后呢图像实际上也有比方说彩色的图像还有灰度的图像，然后也有各种各样的一些信号有这个超声信号电子的，然后包括光学的，然后也包括一些谱那个图谱比方说像这个能谱或者XPS光电子能谱啊这样的一些谱图。那那它的数据实际上是千奇百怪的，而且呢样品的种类也非常非常多，芯片的话其实有可能上万种啊都有可能，就像我们一个手机上面可能都有几百种芯片。有这个模拟芯片数字芯片，然后CPU啊存储器，然后包括有这个电源管理的芯片，那么各种各样的电阻电容这些都是芯片。那不同的芯片呢实际上啊，你获得的这个数据啊，你就不说这个失效品了，就好品的这个数据都是千奇百怪的。然后不同的人拍的这个数据还不一样，有的人可能样品摆的比较正，像我有点强迫症，我一般习惯这个样品要横平竖直的摆，有的人可能就随便的往那一丢，对吧，有的样品他可能还稍微翘起来一点点，所以拍到的这个图片真的就是千奇百怪的。那么其实你用来做这个机器学习训练的话，这种数据往往都是不够好的，而且量也是不够的。如果其实我之前有设想过，如果全世界或者全中国的这个失效分析实验室，那么大家可以共享数据的话啊，实际上这件事还有的做。但是呢大多数芯片公司都是要求保密的，啊就别说别说这个数据了，对吧，你连一只蚊子都飞不出来。像我们原来在三星的时候就后来到什么程度呢，就打印纸都带不出来，我们所有的纸里边都掺了这个金属粉，过安检的时候都会响。所以呢就是基本上是不太现实，所以我也太我也比较理解，就是咱们文献报道的时候，大家在做一些尝试，用这个ANN就只要一层嘛，就可能数据量要求没有那么高，但是呢整体上看它的效果也不是那么太好。但是呢仿真这个确实是之前有想到过，然后也确实看到文献有报道，大家都已经做出来了，也是比较新的一个方向。啊如果说啊有这个高校的从业者啊，或者是有相关行业的经验的人，如果说想往这个方向做的话，我觉得还是值得做的一个方向。

G：然后最后呢其实我想提一点，啊关于行业知识库的这个事情，就是大模型。因为呃从23年年底的时候开始，就是陆陆续续的大家开始用这个大模型。然后我可能用到一些图像处理的算法，图像融合的算法，那之前呢在有GPT之前，其实我是不太敢想的。因为呢一方面确实自己会一点点Python，但是呢想达到文献报道的那个水平是很困难的，就是你得有大段的时间，而且还要有这个就是物理或者这个CV计算机视觉这个领域的一些就是深入的一些就是说学习了或者研究了，你才可能做的出来，对吧。这咱就不说研究了，就是光复现人家文献的这个效果就很困难。但是有了GPT之后，这个这个事已经变得可行了。就像我之前做那个图像融合，我就跟GPT说按照这个mgff给我做一个图像融合，那他就做出来了，然后那个代码居然就能运行，我都没想到。

G：然后呢其实我看到大模型落地，因为用了一年多，我觉得啊行业知识库还是一个确定的落地的方向。而且呢我就想做实际上分析行业的知识库，然后也在往这个方向努力。然后现在来说呢，其实大家都是在上传PDF，但是呢像我自己攒的一些PDF都是电子书比较大，我觉得单篇文献还可以，对吧，十几页，它的识别的水平还比较高一点。但是有一些老文献，比方说他那个文字其实已经拷贝不出来了，然后PDF虽然看上去格式很完善，但实际上有的时候你直接去复制粘贴，你会发现它的文字其实是串行的，就是会会影响一些使用。所以我现在的做法很简单，就是用我们学校学生比较多，就是虽然说水平不高，但是你让他做一些蚂蚁搬家的活还是能做，就是让他给他们一个PDF，比方说找10个人，每个人负责几页，然后用那个DeepL一段一段去翻译，然后再把它保存成Markdown，然后再喂给大模型。我在做这个事情，然后我觉得也蛮快的，一本大概700多页的书，他们几个人大概用了6个人，大概不到一星期就做完了这本书。我自己翻译的话，因为我一直在自己做，我就越翻译越越不想做，翻译就就腻了，就可能原来我想的，可能一天或者三天我能翻完，那么十几页，后来发现三个月一页没动，我说不行，还是要找，还是要找人多。

G：然后他们做完初步的翻译之后呢，我自己再去完善一些，根据我的行业经验，去改善一些这个翻译的这个文字，还是可以做的。然后呢包括啊后续可能会考虑结合这个知识图谱啦，然后包括以图搜图啦，这些附加的这些功能。因为这个呢其实也是出于，就是因为我在企业待过嘛，我知道企业的一些诉求，就最简单的道理，就是数据安全，就是他的数据不想给其他的企业看到。所以呢大部分的企业，特别是韩企日企这种这种公司，他是特别特别反感，就是要要把数据传到网上，然后做这个就是大模型的这种知识问答。所以呢他们大部分都是需要有这个本地化部署的这个要求。所以呢我觉得本地化部署的行业知识库，未来可能是真的是一个很好的一个就是落地的应用的一个方向吧。这当然也是给就是行业的从业者的一些建议。